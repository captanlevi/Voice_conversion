{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder.audio import preprocess_wav\n",
    "from encoder.inference import embed_utterance, load_model as load_embedding_model\n",
    "from pathlib import Path\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "from synthesizer.inference import Synthesizer\n",
    "\n",
    "\n",
    "from vocoder.inference import load_model as load_vocoder , infer_waveform\n",
    "\n",
    "from synthesizer.audio import inv_mel_spectrogram\n",
    "from synthesizer.hparams import hparams\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from joblib import Parallel, delayed\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_path = Path(\"models/encoder.pt\")\n",
    "syn_model_path = Path(\"models/seab_trained/synthesizer.pt\")\n",
    "vocoder_model_path = Path(\"models/vocoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#target_spk_path = \"demo/source/p374_113.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoder \"encoder.pt\" trained to step 1564501\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at models/vocoder.pt\n",
      "Synthesizer using device: cpu\n"
     ]
    }
   ],
   "source": [
    "load_embedding_model(encoder_model_path)\n",
    "load_vocoder(vocoder_model_path)\n",
    "syn = Synthesizer(syn_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wav = preprocess_wav(source_spk_path)\n",
    "#source_spk_embedding = embed_utterance(wav)\n",
    "\n",
    "wav = preprocess_wav(target_spk_path)\n",
    "target_spk_embedding = embed_utterance(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 30.870M\n",
      "Loaded synthesizer \"synthesizer.pt\" trained to step 297000\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "syn_output = syn.synthesize_spectrograms(texts = [\"This cake is great. It's so delicious and moist.\"],embeddings = target_spk_embedding)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mel_gan_vocoder =  torch.hub.load('descriptinc/melgan-neurips', 'load_melgan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#syn_output = np.load(\"models/001/mel-spectrograms/mel-prediction-step-1000_sample_1.npy\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{| ████████████████ 57000/57600 | Batch Size: 6 | Gen Rate: 2.1kHz | }"
     ]
    }
   ],
   "source": [
    "#wav_out = inv_mel_spectrogram(syn_output,hparams= hparams)\n",
    "wav_out= infer_waveform(syn_output)\n",
    "#wav_out = mel_gan_vocoder.inverse(torch.tensor(syn_output).unsqueeze(0)).numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45200,)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write(\"./demo/generated/{}\".format(os.path.split(target_spk_path)[-1]),wav_out,16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VCTK p376 p374 p364 p363 p362 p360 p340 p298 p310 p345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(source_spks,source_dir,dump_dir,target_speechs):\n",
    "\n",
    "    args = []\n",
    "    for source_spk in source_spks:\n",
    "        for index,target_speech in enumerate(target_speechs):\n",
    "            source_spk_path  = os.path.join(source_dir,source_spk)\n",
    "            args.append((source_spk_path,target_speech,index))\n",
    "\n",
    "  \n",
    "\n",
    "    print(args)\n",
    "        \n",
    "\n",
    "    def makeAndWrite(arg):\n",
    "        \n",
    "        load_embedding_model(encoder_model_path)\n",
    "        load_vocoder(vocoder_model_path,verbose= False)\n",
    "        syn = Synthesizer(syn_model_path,verbose= False)\n",
    "\n",
    "        source_spk_path,target_speech,index = arg\n",
    "        wav = preprocess_wav(source_spk_path)\n",
    "        source_spk_embedding = embed_utterance(wav)\n",
    "        syn_output = syn.synthesize_spectrograms(texts = [target_speech],embeddings = source_spk_embedding)[0]\n",
    "\n",
    "        wav_out= infer_waveform(syn_output)\n",
    "        dump_spk_dir = os.path.join(dump_dir,os.path.split(source_spk_path)[1].split(\".wav\")[0])\n",
    "        if(os.path.exists(dump_spk_dir) == False):\n",
    "            os.mkdir(dump_spk_dir)\n",
    "        \n",
    "        name = re.sub(r'[^a-zA-Z0-9_]', '', \"_\".join(target_speech.lower().split()))\n",
    "        dump_path = os.path.join(dump_spk_dir,name+ \".wav\")\n",
    "\n",
    "        sf.write(dump_path,wav_out,16000)\n",
    "\n",
    "\n",
    "    Parallel(n_jobs=-1)(delayed(makeAndWrite)(arg)\n",
    "        for arg in args)\n",
    "    \n",
    "\n",
    "    #for arg in args:\n",
    "    #    makeAndWrite(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_speeches = [\"it took me quite a long time to develop a voice, and now that I have it I'm not going to be silent.\",\n",
    "\"Be a voice, not an echo.\",\n",
    "\"I'm sorry Dave. I'm afraid I can't do that.\",\n",
    "\"This cake is great. It's so delicious and moist.\",\n",
    "\"Prior to November 22, 1963.\"]\n",
    "\n",
    "original_speeches = [\"My ideal morning begins with hot coffee\"]\n",
    "\n",
    "spks = [\"speaker1.wav\", \"speaker2.wav\", \"speaker3.wav\", \"speaker4.wav\", \"speaker5.wav\"]\n",
    "spks = [\"speaker3.wav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('demo/source/speaker3.wav', 'My ideal morning begins with hot coffee', 0)]\n",
      "Loaded encoder \"encoder.pt\" trained to step 1564501\n",
      "Trainable Parameters: 4.481M\n",
      "Trainable Parameters: 30.870M\n"
     ]
    }
   ],
   "source": [
    "infer(source_spks = spks ,source_dir= \"demo/source\", dump_dir= \"demo/generated\",target_speechs= original_speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
